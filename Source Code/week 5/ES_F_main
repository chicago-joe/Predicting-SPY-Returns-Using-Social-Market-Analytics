# ES_F_main.py
#
# analysis of S&P500 E-mini Futures data (ticker: ES_F)
# 15-min data
#
# created by Joseph Loss on 10/14/2019
# contact: loss2@illinois.edu
# 
import pandas as pd
import time
import numpy as np
# import pywt
from datetime import timedelta
import matplotlib.pyplot as plt



raw_ES_F_2015 = 'C://Users//jloss//PyCharmProjects//SMA-HullTrading-Practicum//Source Code//data//F15m2015//ES_F.txt'
raw_ES_F_2016 = 'C://Users//jloss//PyCharmProjects//SMA-HullTrading-Practicum//Source Code//data//F15m2016//ES_F.txt'
raw_ES_F_2017 = 'C://Users//jloss//PyCharmProjects//SMA-HullTrading-Practicum//Source Code//data//F15m2017//ES_F.txt'

column_names = ['ticker', 'date', 'raw-s', 'raw-s-mean', 'raw-volatility', 'raw-score', 's',
                    's-mean', 's-volatility', 's-score', 's-volume', 'sv-mean', 'sv-volatility',
                    'sv-score', 's-dispersion', 's-buzz', 's-delta', 'center-date', 'center-time', 'center-time-zone']

ES_F_2015 = pd.read_csv(raw_ES_F_2015, skiprows = 6, sep = '\t', names = column_names)
ES_F_2016 = pd.read_csv(raw_ES_F_2016, skiprows = 6, sep = '\t', names = column_names)
ES_F_2017 = pd.read_csv(raw_ES_F_2017, skiprows = 6, sep = '\t', names = column_names)

#aggregating data
df_tmp = ES_F_2015.append(ES_F_2016, ignore_index = True)
df_aggregate = df_tmp.append(ES_F_2017, ignore_index = True)
df_datetime = df_aggregate['date'].str.split(' ', n = 1, expand = True )
df_datetime.columns = ['Date', 'Time']
df = pd.merge(df_aggregate, df_datetime, left_index = True, right_index = True)

#filtering based on trading hours and excluding weekends
df = df[(df['Time'] >= '09:24:00') & (df['Time'] <= '16:11:00')]



#excluding weekends
#removing empty columns
df = df.dropna(axis='columns')
df=df.drop(columns=['ticker','center-date','center-time','center-time-zone'])
df["volume_base_s"]=df["raw-s"]/df["s-volume"]



